
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

\chapter{引言}
\label{cha:introdction}

\section{研究背景}
在今天这个数据爆炸的时代，文本、图像、视频以及音频等多媒体数据呈现出指数级的增长。如何快速、准确地从这个海量的互联网数据库中获取我们想要的信息，是我们不得不面对的一个问题。Google\footnote{https://www.google.com}、Bing\footnote{http://cn.bing.com}、Baidu\footnote{https://www.baidu.com} 等提供的文本、图像等搜索引擎服务为我们获取信息带来了极大的便利。而在这些搜索引擎背后的都需要用到的一项技术——\textbf{近似近邻查询}（Approximate Nearest Neighbor Search）。在大规模数据的应用场景下，精确的近似查询需要耗费时间太长，不具有实际应用价值。近似近邻查询可以大幅度缩短查询时间，同时保证查询结果与精确查询结果近似，因此更具有实用性。除了信息检索以外，近似近邻查询技术被广泛应用于计算机视觉、机器学习、数据挖掘、模式识别等领域。

在不考虑时间效率的情况下，近似近邻查询问题可以直接通过一种暴力搜索的方式来解决。比如，我们可以直接计算查询数据$q$与数据集合$S$ 中每一条数据的距离，最终根据距离大小，选取出距离最近的前$n$个数据。但在现实中，由于数据集合$S$的规模非常，这种朴素的方法单词查询的计算时间太长而无法采用。但是，如果从规模比较大的数据集合$S$上删选出一个非常小待选集合$S'$，之后再在集合$S'$上进行朴素的暴力搜索选取出前$n$个近邻数据，这时的暴力搜索的时间效率是可以接受的，整个查询过程的时间效率和准确率就取决于删除出待选集合$S'$的过程。待选集合$S'$大小与查询准确率有着密切关系，一般来说，集合$S'$越大，查询准确率越高，但是最终的暴力搜索阶段的时间会变长；集合$S'$越小，则查询效率越低，暴力搜索阶段的时间越短。因此，如何选择一个大小合适、相关性高的待选集合$S'$就成了近似近邻查询问题的关键。

近年来，近似近邻查询问题一直都是研究热点问题之一。目前，这一技术主要面临一下两大挑战：
\begin{enumerate}
\item 海量

随着互联网上的数据越来越多，需要存储的数据量也越来越大。然而，传统的索引结构一般都是基于小规模数据而设计的单机结构。大规模的数据一般无法做到单机存储，更不用说加载到内存当中索引了。这些数据往往存储于分布式系统当中，同时也需要一种分布式的索引结构来支持查询。海量的数据不仅给存储带来了压力，同时也给实时查询带来了巨大挑战。
\item 维度灾难

在多媒体数据处理过程时，往往都会针对多媒体数据提取特征进行处理。为了更好地刻画数据，一般来说，特征数据的维度越高，刻画的准确性也越高。例如，在图像数据处理过程中，我们常常可能用到的 SIFT、SURF 特征都是 128 维的，GIST 特征有 960 维，而 BOVW（Bag of Visual Words）的维度更是高达成千上万维。如此高维度的数据，仅计算两个向量之间距离的时间消耗就比较长，更不必说在大规模数据上进行查询了。
\end{enumerate}

Spark 是一个基于 MapReduce 的通用的大数据并行计算框架，最初由 UC Berkeley AMP Lab 开发。Spark 的架构是在 Hadoop 基础上的改良，继承了 MapReduce 的优点，它与 Hadoop 最大不同之处就是内存计算，Hadoop 将计算过程的中间数据存储在磁盘上，而 Spark 一般是用内存来存储数据，所有数据操作都在内存中完成。

\section{主要研究内容}
本文的主要的关注点是在高维空间中的近似近邻查询问题，通过研究对比现有的几种最新近似近邻查询方法，了解几种不同方法的优缺点。在 Spark 框架下实现了一种基于向量量化（Vector Quantization）的近似近邻查询方法。最终，通过实验来验证算法的准确性以及测试算法时间效率。

\section{论文组织结构}